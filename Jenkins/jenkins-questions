##########################################################################################
===================================  Jenkins =============================================
##########################################################################################


Jenkins Questions !!

1. How can we trigger a Jenkins build once a commit has been done in source code repository(Git/Svn)? Github-webhook 

2. Explain about CI and CD of your project currently you are working? 
  
Continuous Integration (CI) is a development practice where developers integrate code into a shared repository frequently, get the source code   
  management (scm), then compile then do testing & then finally build. 
  After that static code analysis and push to artifact repository. (If in case build is failure it trigger the failure send 
   notification to respecitive person)



3. In how many ways can we install Jenkins?

4. How do you update Jenkins? Via ui or how?

5. Why we use  SCM plugin ?

6. While updating will you take backup?

7. What is Jenkins server crashed? How do you restore?

8. When new changes in git, How Jenkins trigger the execution of tests on target server?

9. How Jenkins know in which account  (AWs acc) it has to lunch instances to execute the tests? Where you mentioned that details?

10. Explain about Jenkins?

11. What is CI & CD in Devops?

How you have setup the CICD pipeline?

Why jdk can’t be installed thru wget and going for winscp?

If Jenkins we are installing, why git is needed to be install in CICD pipeline.

What are the things are you do in Jenkins?

What do you mean by continues integration and continoues delivery?

What are the most plugins you  used in Jenkins?

For integrating the ansble you have to use some  plugin for  Jenkins?

Do you automated anything in the Jenkins?

5.What level of knowledge you have in Jenkins?

16.In Jenkins ways we can install Jenkins?

Q3. What is Continuous Delivery?
Ans. It is practice of delivering the software for testing as soon as it is built by CI (Continuous Integration) servers.

Q11. Why do you need a Continuous Integration of Dev & Testing?
Ans. Continuous Integration of Dev and Testing improves the quality of software, and reduces the time taken to deliver it, by replacing the traditional practice of testing after completing all development.


Q17. What testing is necessary to insure a new service is ready for production?
Ans. Continuous testing

Q15. What is meant by Continuous Integration?
Ans. It is a development practice that requires developers to integrate code into a shared repository several times a day.

Q18. What is Continuous Testing?
Ans. Continuous Testing is the process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with in the latest build.

Q19. What is Automation Testing?
Ans. Automation testing or Test Automation is a process of automating the manual process to test the application/system under test.

Q20. What are the key elements of continuous testing?
Ans. Risk assessment, policy analysis, requirements traceability, advanced analysis, test optimisation, and service virtualisation

Q21. What are the Testing types supported by Selenium?
Ans. Regression testing and functional testing

1.what is Jenkins? the use of Jenkins?

Jenkins is an open source automation tool written in Java with plugins built for Continuous Integration purpose. 
Jenkins is used to build and test your software projects continuously making it easier for developers to integrate changes to the project, and making it easier for users to obtain a fresh build. 
It also allows you to continuously deliver your software by integrating with a large number of testing and deployment technologies.

Once you have defined Jenkins give an example, you can refer the below mentioned use case:
-----
First, a developer commits the code to the source code repository. Meanwhile, the Jenkins server checks the repository at regular intervals for changes.
Soon after a commit occurs, the Jenkins server detects the changes that have occurred in the source code repository. Jenkins will pull those changes and will start preparing a new build.
If the build fails, then the concerned team will be notified.
If built is successful, then Jenkins deploys the built in the test server.
After testing, Jenkins generates a feedback and then notifies the developers about the build and test results.
It will continue to check the  source code repository for changes made in the source code and the whole process keeps on repeating.


Q22. How to reset jenkins password ?
  1. https://www.browserling.com/tools/bcrypt
  2. cd /var/lib/jenkins/users/admin/
  3. take copy of original file and do modification
  4. paste bycrpt pasword 
  5. restart and jenkins
  6. Now check in broser

==================================================================================================================

These are all question asked by different interviews. If you have any other than these please comment your questions.
Please subscribe my you-tube channel for more upcoming videos for interview questions and real time scenarios hands-on.

1. which tool have you used for implement CI/CD ? 
- Jenkins 
2. Any alternate tool do you know for CI/CD ?
Yes i know, bamboo/uideploy/teamcity/tfs..
These are alternative tools for CICD, I know the functionality of these tools but i didn't get oppertunity to work 
these tools.

3. what is Continuous Integration?  
- Continuous Integration (CI) is a development practice where developers integrate code into a shared repository frequently, get the source code management (scm), then compile then do testing & then finally build. 
  After that static code analysis and push to artifact repository. (If in case build is failure it trigger the failure send 
   notification to respecitive person)
  

4. what type of jobs have you configured in jenkins? 
- Freestyle project , maven project, pipeline, github-webhook ,external job, build flow , multiconfiguration project, 
  mutlibranch pipeline

5. what are the types of jobs are available in jenkins?
-Based on plugins installation will get jobs
Freestyle project , maven project, pipeline, external job, build flow , multiconfiguration project, 
  mutlibranch pipeline

6. what is difference b/w freestyle and pipeline?
freestyle -Configure  throw web-ui 
Jenkins can be used to perform the typical build server work, such as doing continuous/official/nightly builds, run tests, or perform some repetitive batch tasks. This is called "free-style software project" in Jenkins

7. what is pipeline?
- Pipeline is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.
A Pipeline’s code defines your entire build process, which typically includes stages for building an application, testing it and then delivering it.
 
A node is a machine which is part of the Jenkins environment and is capable of executing a Pipeline.

8. what is declarative pipeline? 
In Declarative Pipeline syntax, the pipeline block defines all the work done throughout your entire Pipeline.
Jenkinsfile (Declarative Pipeline)
pipeline {
    agent any 
    stages {
        stage('Build') { 
            steps {
                // 
            }
        }
        stage('Test') { 
            steps {
                // 
            }
        }
        stage('Deploy') { 
            steps {
                // 
            }
        }
    }
}

9. what is difference between  declarative pipeline and script based pipeline?

In Scripted Pipeline syntax, one or more node blocks do the core work throughout the entire Pipeline


Jenkinsfile (Scripted Pipeline)
node {  
    stage('Build') { 
        // 
    }
    stage('Test') { 
        // 
    }
    stage('Deploy') { 
        // 
    }
}



10. write the pipeline syntax?
above syntax

11. what is master/slave architecture? what is the use of master/slave?
 multiple master and mutliple slaves can be configured
Jenkins master/slave architecture is used for distributed build environments, where the workload of building projects is distributed to multiple agent nodes, and we can use different environments for each build
Jenkins supports the master-slave architecture, i.e. many slaves work for a master. It is also known as Jenkins Distributed Builds. It also allows you to run jobs on different environments like Linux, Windows, MacOS, etc


12. How many we can connect the slaves?
we can launch agent 
1. via java web start
2. agent via ssh 
3. via execution of command  on the master
4. control this windows slave as windows service
	

13. How many ways we can provide security for your jenkins server?


14. what is sonarqube ? have you configure ? How you configure ?
SonarQube provides the capability to not only show health of an application but also to highlight issues newly introduced. With a Quality Gate in place, you can fix the leak and therefore improve code quality systematically.

15. what type of artifactory repository tool have you used? Nexus/jfrog/s3   (os and pro version are available for nexus and jfrog wheares s3 charges only for transfering and retriving of data )

16. what is the use of artifactory tools?
Jenkins stores the artifacts as plain files without versioning while artifacts in an artifact repository can be version controlled
 To maintain multiple version of artifacts for delevery purpose
Its one kind of repositary use to store our war/jar files . If 

17. How you declare a variables in pipeline?
To run only pipeline script . install plugin pipline and select the new item job using piplene ok.
Also select pipeline script from scm then scm " git " 
repositoray url  , credenital  done



18. what is DSL language? domain spcific language? domain specific language (groovi language)
uses pipeline plugin using groovi . In the pipeline  the syntax decalaring called as declartive lang. 
java code/shell script / bat scripts are used
 
19. what is upstream/downstream projects? what is the use of it? which scenario you configure?


20. If a have 10 repositories i github how many jobs you can configure? For 10 repo 10 jobs required
21. Dou you have experience to install jenkins? yes
22. How you configure jdk,maven,gradle...etc? jenkins->managejenkins-> jdk installation  (path )
23. In my environment i have different version for java implementation projects is there ? How you configure multiple jdk's?
jenkins->managejenkins-> jdk installation-> Add jdk (1.8) or Add jdk (1.7) or Add jdk (1.6)

24. what are the plugins have you used in your project? maven plugin , pipeline, publish over ssh, git and so on
25. How to take backup my jenkins? thin backup plugin or else we can write shell script to take /var/lib/jenkins this backup folder
26. what is jenkins Home directory?  .jenkins folder 
27. How to deleted old builds automatically?
28. How to configure multiple environment deployment?



====================================================================================
1. what is jenkins?
	jenkins is a continous integration tool written in java.
	It keep track on version control system
	Jenkins is an open source tool

2. How can you setup jenkins jobs?
	a. select new item from the nenu
	b. name of job and select which style(free or maven or )
	c. ok new job
	d. now configure job

3. How to status or start or restart jenkins ?
/etc/init.d/jenkins status  or sudo service jenkins status
jenkins_url)/ restart(forces a restart without waiting for builds to complete)
      or saferestart(allows all running builds to complete)

4. Mainly required components in jenkins?
	version control system like git, svn
        build tools like apache maven

5. various ways to schedule a job in jenkins?
	Downstream: after completion of other builds
	source code commits
	sheduled to run at specified time
	manual build

6. Difference between maven ant and jenkins
	maven and ant are build tools 
	jenkins is open source continous integration tool

what is CI?
CI is a strategy of constantly mergin development work with a maser/branch
so that you can test changes and test tat changes work with other changes

============================================================================================

Docker (software) Interview Questions
Docker (software) Tutorial
 
 Docker (software) Jobs
 
 All Interview Questions
Question 1. What Is Docker?
Answer :
Docker is a platform to run each application isolated(seperately) and securely. Internally it achieves it by using kernel containerization feature.

Question 2. What Is The Advantage Of Docker Over Hypervisors?
Answer :
Docker is light weight and more efficient in terms of resource uses because it uses the host underlying kernel rather than creating its own hypervisor.

Question 3. What Is Docker Container?
Answer :
Docker Container is the instantiation of docker image. In other words, it is the run time instance of images. Images are set of files whereas containers is the one who run the image inside isolated.

 
Question 4. Is Container Technology New?
Answer :
No, it is not. Different variations of containers technology were out there in *NIX world for a long time.Examples are:-Solaris container (aka Solaris Zones)-FreeBSD Jails-AIX Workload Partitions (aka WPARs)-Linux OpenVZ.

Question 5. How Is Docker Different From Other Container Technologies?
Answer :
Well, Docker is a quite fresh project. It was created in the Era of Cloud, so a lot of things are done much nicer than in other container technologies. Team behind Docker looks to be full of enthusiasm, which is of course very good.I am not going to list all the features of Docker here but i will mention those which are important to me.
Docker can run on any infrastructure, you can run docker on your laptop or you can run it in the cloud.
Docker has a Container HUB, it is basically a repository of containers which you can download and use. You can even share containers with your applications.
Docker is quite well documented.

Question 6. Difference Between Docker Image And Container?
Answer :
Docker container is the runtime instance of docker image.
Docker Image does not have a state and its state never changes as it is just set of files whereas docker container has its execution state.

 
Question 7. What Is The Use Case For Docker?
Answer :
Well, I think, docker is extremely useful in development environments. Especially for testing purposes. You can deploy and re-deploy apps in a blink of eye.
Also, I believe there are use cases where you can use Docker in production. Imagine you have some Node.js application providing some services on web. Do you really need to run full OS for this
Eventually, if docker is good or not should be decided on an application basis. For some apps it can be sufficient, for others not.

Question 8. How Exactly Containers (docker In Our Case) Are Different From Hypervisor Virtualization (vsphere)? What Are The Benefits?
Answer :
To run an application in virtualized environment (e.g. vSphere), we first need to create a VM, install an OS inside and only then deploy the application.To run same application in docker all you need is to deploy that application in Docker. There is no need of additional OS layer. You just deploy the application with its dependent libraries, the rest (kernel, etc.) is provided by Docker engine.This table from a Docker official website shows it in a quite clear way.
Another benefit of Docker, from my perspective, is speed of deployment. Lets imagine a scenario:
ACME inc. needs to virtualize application GOOD APP for testing purposes.
Conditions are:
Application should run in an isolated environment.
Application should be available to be redeployed at any moment in a very fast manner.

Solution 1.
In vSphere world what we would usually do, is:
Deploy OS in a VM running on vSphere.
Deploy an application inside OS.
Create a template.
Redeploy the template in case of need. Time of redeployment around 5-10 minutes.
Sounds great! Having app up and running in an hour and then being able to redeploy it in 5 minutes.

Solution 2.
-Deploy Docker.
-Deploy the app GOODAPP in container.
-Redeploy the container with app when needed.
Benefits: No need of deploying full OS for each instance of the application. Deploying a container takes seconds.

Question 9. How Did You Become Involved With The Docker Project?
Answer :
I came across Docker not long after Solomon open sourced it. I knew a bit about LXC and containers (a past life includes working on Solaris Zones and LPAR on IBM hardware too), and so I decided to try it out. I was blown away by how easy it was to use. My prior interactions with containers had left me with the feeling they were complex creatures that needed a lot of tuning and nurturing. Docker just worked out of the box. Once I saw that and then saw the CI/CD-centric workflow that Docker was building on top I was sold.

 
Question 10. Docker Is The New Craze In Virtualization And Cloud Computing. Why Are People So Excited About It?
Answer :
I think it’s the lightweight nature of Docker combined with the workflow. It’s fast, easy to use and a developer-centric DevOps-ish tool. Its mission is basically: make it easy to package and ship code. Developers want tools that abstract away a lot of the details of that process. They just want to see their code working. That leads to all sorts of conflicts with Sys Admins when code is shipped around and turns out not to work somewhere other than the developer’s environment. Docker turns to work around that by making your code as portable as possible and making that portability user friendly and simple.

Question 11. What, In Your Opinion, Is The Most Exciting Potential Use For Docker?
Answer :
It’s definitely the build pipeline. I mean I see a lot of folks doing hyper-scaling with containers, indeed you can get a lot of containers on a host and they are blindingly fast. But that doesn’t excite me as much as people using it to automate their dev-test-build pipeline.
Question 12. How Is Docker Different From Standard Virtualization?
Answer :
Docker is operating system level virtualization. Unlike hypervisor virtualization, where virtual machines run on physical hardware via an intermediation layer (“the hypervisor”), containers instead run user space on top of an operating system’s kernel. That makes them very lightweight and very fast.

 
Question 13. Do You Think Cloud Technology Development Has Been Heavily Influenced By Open Source Development?
Answer :
I think open source software is closely tied to cloud computing. Both in terms of the software running in the cloud and the development models that have enabled the cloud. Open source software is cheap, it’s usually low friction both from an efficiency and a licensing perspective.

Question 14. How Do You Think Docker Will Change Virtualization And Cloud Environments? Do You Think Cloud Technology Has A Set Trajectory, Or Is There Still Room For Significant Change?
Answer :
I think there are a lot of workloads that Docker is ideal for, as I mentioned earlier both in the hyper-scale world of many containers and in the dev-test-build use case. I fully expect a lot of companies and vendors to embrace Docker as an alternative form of virtualization on both bare metal and in the cloud.
As for cloud technology’s trajectory. I think we’ve seen significant change in the last couple of years. I think they’ll be a bunch more before we’re done. The question of OpenStack and whether it will succeed as an IAAS alternative or DIY cloud solution.
I think we’ve only touched on the potential for PAAS and there’s a lot of room for growth and development in that space. It’ll also be interesting to see how the capabilities of PAAS products develop and whether they grow to embrace or connect with consumer cloud-based products.
Question 15. Can You Give Us A Quick Rundown Of What We Should Expect From Your Docker Presentation At Oscon This Year?
Answer :
It’s very much a crash course introduction to Docker. It’s aimed at Developers and SysAdmins who want to get started with Docker in a very hands on way. We’ll teach the basics of how to use Docker and how to integrate it into your daily workflow.

 
Question 16. Your Bio Says “for A Real Job” You’re The Vp Of Services For Docker. Do You Consider Your Other Open Source Work A Hobby?
Answer :
That’s mostly a joke related to my partner. Like a lot of geeks, I’m often on my computer, tapping away at a problem or writing something. My partner jokes that I have two jobs: my “real” job and my open source job. Thankfully over the last few years, at places like Puppet Labs and Docker, I’ve been able to combine my passion with my paycheck.
Question 17. Why Is Docker The New Craze In Virtualization And Cloud Computing?
Answer :
It’s OSCON time again, and this year the tech sector is abuzz with talk of cloud infrastructure. One of the more interesting startups is Docker, an ultra-lightweight containerization app that’s brimming with potential
I caught up with the VP of Services for Docker, James Turnbull, who’ll be running a Docker crash course at the con. Besides finding out what Docker is anyway, we discussed the cloud, open source contributing, and getting a real job.
Question 18. Why Do My Services Take 10 Seconds To Recreate Or Stop?
Answer :
Compose stop attempts to stop a container by sending a SIGTERM. It then waits for a default timeout of 10 seconds. After the timeout, a SIGKILL is sent to the container to forcefully kill it. If you are waiting for this timeout, it means that your containers aren’t shutting down when they receive the SIGTERM signal.
There has already been a lot written about this problem of processes handling signals in containers.
To fix this problem, try the following:
Make sure you’re using the JSON form of CMD and ENTRYPOINT in your Dockerfile.
For example: use ["program", "arg1", "arg2"] not"program arg1 arg2". Using the string form causes Docker to run your process using bash which doesn’t handle signals properly. Compose always uses the JSON form, so don’t worry if you override the command or entrypoint in your Compose file.
If you are able, modify the application that you’re running to add an explicit signal handler for SIGTERM.
Set the stop_signal to a signal which the application knows how to handle:
web: build: . stop_signal: SIGINT
If you can’t modify the application, wrap the application in a lightweight init system (like s6) or a signal proxy (like dumb-init or tini). Either of these wrappers take care of handling SIGTERM properly.
Question 19. How Do I Run Multiple Copies Of A Compose File On The Same Host?
Answer :
Compose uses the project name to create unique identifiers for all of a project’s containers and other resources. To run multiple copies of a project, set a custom project name using the -p command line option or theCOMPOSE_PROJECT_NAME environment variable.
Question 20. What’s The Difference Between Up,run, And Start?
Answer :
Typically, you want docker-compose up. Use up to start or restart all the services defined in a docker-compose.yml. In the default “attached” mode, you’ll see all the logs from all the containers. In “detached” mode (-d), Compose exits after starting the containers, but the containers continue to run in the background.
The docker-compose run command is for running “one-off” or “adhoc” tasks. It requires the service name you want to run and only starts containers for services that the running service depends on. Use run to run tests or perform an administrative task such as removing or adding data to a data volume container. The run command acts like docker run -ti in that it opens an interactive terminal to the container and returns an exit status matching the exit status of the process in the container.
The docker-compose start command is useful only to restart containers that were previously created, but were stopped. It never creates new containers.
Question 21. Can I Use Json Instead Of Yaml For My Compose File?
Answer :
Yes. Yaml is a superset of json so any JSON file should be valid Yaml. To use a JSON file with Compose, specify the filename to use.
for example:
docker-compose -f docker-compose.json up
Question 22. Should I Include My Code With Copy/add Or A Volume?
Answer :
You can add your code to the image using COPY or ADD directive in a Dockerfile. This is useful if you need to relocate your code along with the Docker image, for example when you’re sending code to another environment (production, CI, etc).
You should use a volume if you want to make changes to your code and see them reflected immediately, for example when you’re developing code and your server supports hot code reloading or live-reload.
There may be cases where you’ll want to use both. You can have the image include the code using a COPY, and use a volume in your Compose file to include the code from the host during development. The volume overrides the directory contents of the image.
Question 23. Where Can I Find Example Compose Files?
Answer :
There are many examples of Compose files on github.
Compose documentation:
Installing Compose
Get started with Django
Get started with Rails
Get started with WordPress
Command line reference
Compose file reference
Question 24. Are You Operationally Prepared To Manage Multiple Languages/libraries/repositories?
Answer :
Last year, we encountered an organization that developed a modular application while allowing developers to “use what they want” to build individual components. It was a nice concept but a total organizational nightmare — chasing the ideal of modular design without considering the impact of this complexity on their operations.
The organization was then interested in Docker to help facilitate deployments, but we strongly recommended that this organization not use Docker before addressing the root issues.
Making it easier to deploy these disparate applications wouldn’t be an antidote to the difficulties of maintaining several different development stacks for long-term maintenance of these apps.
Question 25. Do You Already Have A Logging, Monitoring, Or Mature Deployment Solution?
Answer :
Chances are that your application already has a framework for shipping logs and backing up data to the right places at the right times. To implement Docker, you not only need to replicate the logging behavior you expect in your virtual machine environment, but you also need to prepare your compliance or governance team for these changes.
New tools are entering the Docker space all the time, but many do not match the stability and maturity of existing solutions. Partial updates, rollbacks and other common deployment tasks may need to be reengineered to accommodate a containerized deployment.
If it’s not broken, don’t fix it. If you’ve already invested the engineering time required to build a continuous integration/continuous delivery (CI/CD) pipeline, containerizing legacy apps may not be worth the time investment.
Question 26. Will Cloud Automation Overtake Containerization?
Answer :
At AWS Re:Invent last month, Amazon chief technology officer Werner Vogels spent a significant portion of his keynote on AWS Lambda, an automation tool that deploys infrastructure based on your code. While Vogels did mention AWS’ container service, his focus on Lambda implies that he believes dealing with zero infrastructure is preferable to configuring and deploying containers for most developers.
Containers are rapidly gaining popularity in the enterprise, and are sure to be an essential part of many professional CI/CD pipelines. But as technology experts and CTOs, it is our responsibility to challenge new methodologies and services and properly weigh the risks of early adoption. I believe Docker can be extremely effective for organizations that understand the consequences of containerization.
Question 27. You Say That Ansible Can Take Up To 20x Longer To Provision, But Why?
Answer :
Docker uses cache to speed up builds significantly. Every command in Dockerfile is build in another docker container and it’s results are stored in separate layer. Layers are built on top of each other.
Docker scans Dockerfile and try to execute each steps one after another, before executing it probes if this layer is already in cache. When cache is hit, building step is skipped and from user perspective is almost instant.
When you build your Dockerfile in a way that the most changing things such as application source code are on the bottom, you would experience instant builds.
You can learn more about caching in docker in this article.
Another way of amazingly fast building docker images is using good base image – which you specify inFROM command, you can then only make necessary changes, not rebuild everything from scratch. This way, build will be quicker. It’s especially beneficial if you have a host without the cache like Continuous Integration server.
Summing up, building docker images with Dockerfile is faster than provisioning with ansible, because of using docker cache and good base images. Moreover you can completely eliminate provisioning, by using ready to use configured images such stgresus.
$ docker run --name some-postgres -d postgres No installing postgres at all - it's ready to run.
Question 28. Also You Mention That Docker Allows Multiple Apps To Run On One Server.?
Answer :
It depends on your use case. You probably should split different components into separate containers. It will give you more flexibility.
Docker is very lightweight and running containers is cheap, especially if you store them in RAM – it’s possible to spawn new container for every http callback, however it’s not very practical.
At work I develop using set of five different types of containers linked together.
In production some of them are actually replaced by real machines or even clusters of machine – however settings on application level don’t change.
Here you can read more about linking containers.
It’s possible, because everything is communicating over the network. When you specify links in dockerrun command – docker bridges containers and injects environment variables with information about IPs and ports of linked children into the parent container.
This way, in my app settings file, I can read those values from environment. In python it would be:
import os VARIABLE = os.environ.get('VARIABLE')
There is a tool which greatly simplifies working with docker containers, linking included. It’s called fig and you can read more about it here.
Question 29. Finally, What Does The Deploy Process Look Like For Dockerized Apps Stored In A Git Repo?
Answer :
It depends how your production environment looks like.
Example deploy process may look like this:
Build an app using docker build . in the code directory.
Test an image.
Push the new image out to registry docker push myorg/myimage.
Notify remote app server to pull image from registry and run it (you can also do it directly using some configuration management tool).
Swap ports in a http proxy.
Stop the old container.
You can consider using amazon elastic beanstalk with docker or dokku.
Elastic beanstalk is a powerful beast and will do most of deployment for you and provide features such as autoscaling, rolling updates, zero deployment deployments and more.
Dokku is very simple platform as a service similar to heroku.

